# Environment Variables Template
# Copy this file to .env.local and fill in your actual values

# LLM Provider API Keys
GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Application Settings
APP_NAME="Resume Backend API"
DEBUG=true
HOST=0.0.0.0
PORT=8000

# Data Directory
DATA_DIR=./data

# Optional: Logging
LOG_LEVEL=INFO
RENDER_BASE_URL=https://api.render.com
RENDER_TIMEOUT=30
RENDER_MAX_RETRIES=3

# Local AI Settings
LOCAL_MODEL_PATH=
LOCAL_MODEL_NAME=llama-2-7b-chat
LOCAL_TEMPERATURE=0.7
LOCAL_MAX_TOKENS=512
LOCAL_DEVICE=cpu

# AI Features
ENABLE_CACHING=true
CACHE_TTL=3600

# Logging
LOG_LEVEL=INFO
LOG_FILE=app.log

# Data Directory
DATA_DIR=./data

# Security (Optional)
SECRET_KEY=your-secret-key-here
API_KEY=your-api-key-here

# Database (Future)
DATABASE_URL=

# External APIs (Future)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
